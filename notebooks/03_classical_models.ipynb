{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGke5R75FGuX"
   },
   "source": [
    "# Classical ML Benchmark\n",
    "In this notebook I want to test some classical machine learning models on the cleaned tweets.  \n",
    "The goal is to see how Logistic Regression, SVM, Naive Bayes, and Random Forest perform on detecting different types of cyberbullying.  \n",
    "Later I’ll compare these results with transformer-based models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 100,
     "status": "ok",
     "timestamp": 1757288503679,
     "user": {
      "displayName": "Nesrine Ben Tmessek",
      "userId": "09180466627683816099"
     },
     "user_tz": -120
    },
    "id": "DDaHun_RtJID"
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"clean_tweets.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhC_eJOIFued"
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "Here we convert the tweets into numerical features and we also encode the target labels into numbers.\n",
    "TF-IDF creates the input features, and LabelEncoder makes the categories numeric.  \n",
    "Now `X` and `y` are ready for training.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6682,
     "status": "ok",
     "timestamp": 1757286096593,
     "user": {
      "displayName": "Nesrine Ben Tmessek",
      "userId": "09180466627683816099"
     },
     "user_tz": -120
    },
    "id": "y68n9rofFuo3"
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['tweet_text'])\n",
    "\n",
    "# convert text into numerical features\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "x = vectorizer.fit_transform(df['tweet_text'])\n",
    "\n",
    "# cncode the labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['cyberbullying_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhWdqtPHHaHp"
   },
   "source": [
    "## Splitting data into training and testing sets\n",
    "\n",
    "80/20 split to keep the class distribution balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1757286121709,
     "user": {
      "displayName": "Nesrine Ben Tmessek",
      "userId": "09180466627683816099"
     },
     "user_tz": -120
    },
    "id": "XZVhQ0iZY9Nb",
    "outputId": "10d94872-9f7e-43e4-84ab-bc4d0438e391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training feature matrix shape: (35643, 5000)\n",
      "Training labels shape: (35643,)\n",
      "Testing feature matrix shape: (8911, 5000)\n",
      "Testing labels shape: (8911,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training feature matrix shape:\", x_train.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "\n",
    "print(\"Testing feature matrix shape:\", x_test.shape)\n",
    "print(\"Testing labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FeILEbIzJMAo"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4706,
     "status": "ok",
     "timestamp": 1757288512376,
     "user": {
      "displayName": "Nesrine Ben Tmessek",
      "userId": "09180466627683816099"
     },
     "user_tz": -120
    },
    "id": "DDqCpNzAJMSm",
    "outputId": "cc853fc3-d0da-4c9c-84ec-8949467a4b80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                age       0.95      0.97      0.96      1588\n",
      "          ethnicity       0.98      0.98      0.98      1501\n",
      "             gender       0.91      0.83      0.87      1527\n",
      "  not_cyberbullying       0.54      0.51      0.52      1322\n",
      "other_cyberbullying       0.59      0.67      0.62      1379\n",
      "           religion       0.94      0.94      0.94      1594\n",
      "\n",
      "           accuracy                           0.83      8911\n",
      "          macro avg       0.82      0.82      0.82      8911\n",
      "       weighted avg       0.83      0.83      0.83      8911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=500)\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(x_test)\n",
    "\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isH4GcaJULo7"
   },
   "source": [
    "- Strong performance on attribute-specific bullying (age/ethnicity/religion: F1 >0.94).\n",
    "- Weaker on performance non/vague bullying (F1 ~0.52–0.62)\n",
    "- Confusion matrix highlights misclassifications between not/other_cyberbullying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdwLB41GUVyF"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 175716,
     "status": "ok",
     "timestamp": 1757286798237,
     "user": {
      "displayName": "Nesrine Ben Tmessek",
      "userId": "09180466627683816099"
     },
     "user_tz": -120
    },
    "id": "XC65MgpkUUvJ",
    "outputId": "302be877-13b4-430f-df96-288d4d19f326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                age       0.97      0.98      0.97      1588\n",
      "          ethnicity       0.98      0.98      0.98      1501\n",
      "             gender       0.91      0.84      0.87      1527\n",
      "  not_cyberbullying       0.56      0.50      0.53      1322\n",
      "other_cyberbullying       0.59      0.73      0.65      1379\n",
      "           religion       0.96      0.93      0.95      1594\n",
      "\n",
      "           accuracy                           0.84      8911\n",
      "          macro avg       0.83      0.82      0.83      8911\n",
      "       weighted avg       0.84      0.84      0.84      8911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='linear')\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "y_pred_svm = svm.predict(x_test)\n",
    "\n",
    "print(\"SVM Results:\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYhstJHSWRKx"
   },
   "source": [
    "- SVM slightly outperforms logistic regression (84% vs. 83% accuracy).\n",
    "- Strong on attribute-specific classes (age/ethnicity/religion: F1 >0.95).\n",
    "- Improved recall for other cyberbullying\n",
    "- still weak on not cyberbullying (F1 0.53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Cru7F0DWdhK"
   },
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1757286928258,
     "user": {
      "displayName": "Nesrine Ben Tmessek",
      "userId": "09180466627683816099"
     },
     "user_tz": -120
    },
    "id": "aeKL6s_WWdvh",
    "outputId": "814a2516-00fa-45bd-a723-8d5fe21cfd32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Results:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                age       0.83      0.94      0.88      1588\n",
      "          ethnicity       0.90      0.91      0.90      1501\n",
      "             gender       0.86      0.78      0.82      1527\n",
      "  not_cyberbullying       0.53      0.37      0.44      1322\n",
      "other_cyberbullying       0.57      0.55      0.56      1379\n",
      "           religion       0.78      0.95      0.86      1594\n",
      "\n",
      "           accuracy                           0.76      8911\n",
      "          macro avg       0.74      0.75      0.74      8911\n",
      "       weighted avg       0.75      0.76      0.75      8911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(x_train, y_train)\n",
    "\n",
    "y_pred_nb = nb.predict(x_test)\n",
    "\n",
    "print(\"Naive Bayes Results:\")\n",
    "print(classification_report(y_test, y_pred_nb, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8F-Bn1-1d9L_"
   },
   "source": [
    "- Decent performance on attribute-specific bullying with high recall but moderate precision.\n",
    "- Poor on non/vague bullying (F1 0.44–0.56), especially low recall for not_cyberbullying (0.37).\n",
    "- Model underperforms compared to logistic regression and SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87bC5l1SXgj4"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 156668,
     "status": "ok",
     "timestamp": 1757287455091,
     "user": {
      "displayName": "Nesrine Ben Tmessek",
      "userId": "09180466627683816099"
     },
     "user_tz": -120
    },
    "id": "PLHKSdHnXgvv",
    "outputId": "0975e926-2041-4311-caed-57478fab325c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                age       0.96      0.98      0.97      1588\n",
      "          ethnicity       0.98      0.98      0.98      1501\n",
      "             gender       0.90      0.82      0.86      1527\n",
      "  not_cyberbullying       0.52      0.42      0.47      1322\n",
      "other_cyberbullying       0.53      0.66      0.59      1379\n",
      "           religion       0.95      0.95      0.95      1594\n",
      "\n",
      "           accuracy                           0.82      8911\n",
      "          macro avg       0.81      0.80      0.80      8911\n",
      "       weighted avg       0.82      0.82      0.81      8911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(x_test)\n",
    "\n",
    "print(\"Random Forest Results:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmmuw_9tgTCs"
   },
   "source": [
    "- Excellent on attribute-specific bullying (F1 0.95–0.98) with very high precision/recall\n",
    "- Struggles with non/vague bullying (F1 0.47–0.59)\n",
    "- Close to logistic regressionbut slightly lower than naive bayes on some specifics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gryd_aPocFda"
   },
   "source": [
    "## Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 91,
     "status": "ok",
     "timestamp": 1757288521962,
     "user": {
      "displayName": "Nesrine Ben Tmessek",
      "userId": "09180466627683816099"
     },
     "user_tz": -120
    },
    "id": "wouFRDbxcFpT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "import time\n",
    "\n",
    "# collect metrics for each model\n",
    "results = []\n",
    "\n",
    "def add_results(name, y_true, y_pred):\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"F1-macro\": f1_score(y_true, y_pred, average='macro'),\n",
    "        \"F1-weighted\": f1_score(y_true, y_pred, average='weighted'),\n",
    "        \"Precision-macro\": precision_score(y_true, y_pred, average='macro'),\n",
    "        \"Precision-weighted\": precision_score(y_true, y_pred, average='weighted'),\n",
    "        \"Recall-macro\": recall_score(y_true, y_pred, average='macro'),\n",
    "        \"Recall-weighted\": recall_score(y_true, y_pred, average='weighted')\n",
    "    })\n",
    "\n",
    "# add all models\n",
    "add_results(\"Logistic Regression\", y_test, y_pred_lr)\n",
    "add_results(\"SVM\", y_test, y_pred_svm)\n",
    "add_results(\"Naive Bayes\", y_test, y_pred_nb)\n",
    "add_results(\"Random Forest\", y_test, y_pred_rf)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# display results\n",
    "results_df\n",
    "\n",
    "# save results\n",
    "results_df.to_csv(\"classical_models_metrics.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOaEY4tPWaYXRs3TO6kyhwP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
