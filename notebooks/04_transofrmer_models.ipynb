{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrlcM4g0fVTu"
   },
   "source": [
    "# Transformer Benchmark\n",
    "\n",
    "In this notebook, we will train and evaluate different transformer models on our cleaned cyberbullying tweet dataset.\n",
    "We will try BERT-base, DistilBERT, and RoBERTa. We want to compare their performance in classifying tweets .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "df = pd.read_csv(\"clean_tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NvlRBUPfZI6"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['tweet_text'])\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['cyberbullying_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQuUnqrOl5hI"
   },
   "source": [
    "## Splitting data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['tweet_text'], df['label'], test_size=0.2, stratify=df['label'], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ow6C82jmK6v"
   },
   "source": [
    "## Create Dataset Class\n",
    "\n",
    "We create a PyTorch dataset class to use with the HuggingFace Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyberbullyingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLUHhUpymUEs"
   },
   "source": [
    "## BERT-base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsaoWu92miqt"
   },
   "source": [
    "1. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe95220495844f981f9a07f3b16ea3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae860332bd5848b888080d6585e3ba06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811c52489f17443a80f781d9f99267d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc4b6e5c03e49439ca32fac49cdba7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_bert = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "train_encodings_bert = tokenizer_bert(list(train_texts), truncation=True, padding=True, max_length=128)\n",
    "test_encodings_bert = tokenizer_bert(list(test_texts), truncation=True, padding=True, max_length=128)\n",
    "\n",
    "train_dataset_bert = CyberbullyingDataset(train_encodings_bert, list(train_labels))\n",
    "test_dataset_bert = CyberbullyingDataset(test_encodings_bert, list(test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1aqbT75obPd"
   },
   "source": [
    "2. Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32da317be5a44f9a33fc76a8bb4e2d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_bert = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", num_labels=len(le.classes_)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rWB47oeoltj"
   },
   "source": [
    "3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-732820946.py:11: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_bert = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4456' max='4456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4456/4456 27:01, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.359600</td>\n",
       "      <td>0.370921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.360307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4456, training_loss=0.3464805681786803, metrics={'train_runtime': 1622.3171, 'train_samples_per_second': 43.941, 'train_steps_per_second': 2.747, 'total_flos': 3736707905000592.0, 'train_loss': 0.3464805681786803, 'epoch': 2.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args_bert = TrainingArguments(\n",
    "    output_dir='./bert_results',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_dir='./bert_logs',\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "trainer_bert = Trainer(\n",
    "    model=model_bert,\n",
    "    args=training_args_bert,\n",
    "    train_dataset=train_dataset_bert,\n",
    "    eval_dataset=test_dataset_bert,\n",
    "    tokenizer=tokenizer_bert\n",
    ")\n",
    "\n",
    "trainer_bert.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgZLoP1LUiRw"
   },
   "source": [
    "- Train loss fell to 0.25 by end but validation rose slightly which hints at minor overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqANS3CupkfG"
   },
   "source": [
    "4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                age       0.99      0.98      0.98      1588\n",
      "          ethnicity       0.98      0.99      0.98      1501\n",
      "             gender       0.90      0.89      0.89      1527\n",
      "  not_cyberbullying       0.67      0.55      0.60      1322\n",
      "other_cyberbullying       0.66      0.77      0.71      1379\n",
      "           religion       0.95      0.97      0.96      1594\n",
      "\n",
      "           accuracy                           0.87      8911\n",
      "          macro avg       0.86      0.86      0.85      8911\n",
      "       weighted avg       0.87      0.87      0.86      8911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_bert = trainer_bert.predict(test_dataset_bert)\n",
    "y_pred_bert = np.argmax(preds_bert.predictions, axis=1)\n",
    "\n",
    "print(classification_report(test_labels, y_pred_bert, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ym0XnALtVv4O"
   },
   "source": [
    "- Outstanding on type specific bullying( F1 0.96–0.99) with good precision and recall\n",
    "\n",
    "- average handling of non/vague bullying (F1 0.60–0.71) though recall for vague tweets (0.54) is moderate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfHa4cjYp_XW"
   },
   "source": [
    "## DistilBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGRuuQ6OqcLV"
   },
   "source": [
    "1. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45875291c8c4793ace9da02657964c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1002676904504bca8bc5d0ef5bcae1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e808230476e4e329c5fafdfcc354e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e991c8c809c4973966da7f906a3a026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_distil = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "train_encodings_distil = tokenizer_distil(list(train_texts), truncation=True, padding=True, max_length=128)\n",
    "test_encodings_distil = tokenizer_distil(list(test_texts), truncation=True, padding=True, max_length=128)\n",
    "\n",
    "train_dataset_distil = CyberbullyingDataset(train_encodings_distil, list(train_labels))\n",
    "test_dataset_distil = CyberbullyingDataset(test_encodings_distil, list(test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAS8HqIfsD3t"
   },
   "source": [
    "2. Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e707c497bc414c5db083ddbd2bc36528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_distil = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=len(le.classes_)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fM_vyjsWsIeH"
   },
   "source": [
    "3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-2605276030.py:11: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_distil = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4456' max='4456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4456/4456 13:30, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.363800</td>\n",
       "      <td>0.355017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.258600</td>\n",
       "      <td>0.356357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4456, training_loss=0.3467179252172501, metrics={'train_runtime': 810.2524, 'train_samples_per_second': 87.98, 'train_steps_per_second': 5.5, 'total_flos': 1881370993665168.0, 'train_loss': 0.3467179252172501, 'epoch': 2.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args_distil = TrainingArguments(\n",
    "    output_dir='./distilbert_results',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_dir='./distilbert_logs',\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "trainer_distil = Trainer(\n",
    "    model=model_distil,\n",
    "    args=training_args_distil,\n",
    "    train_dataset=train_dataset_distil,\n",
    "    eval_dataset=test_dataset_distil,\n",
    "    tokenizer=tokenizer_distil\n",
    ")\n",
    "\n",
    "trainer_distil.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pcbg81uisNMV"
   },
   "source": [
    "4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                age       0.99      0.98      0.98      1588\n",
      "          ethnicity       0.98      0.99      0.99      1501\n",
      "             gender       0.88      0.89      0.89      1527\n",
      "  not_cyberbullying       0.67      0.53      0.59      1322\n",
      "other_cyberbullying       0.66      0.77      0.71      1379\n",
      "           religion       0.96      0.97      0.96      1594\n",
      "\n",
      "           accuracy                           0.87      8911\n",
      "          macro avg       0.86      0.85      0.85      8911\n",
      "       weighted avg       0.86      0.87      0.86      8911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_distil = trainer_distil.predict(test_dataset_distil)\n",
    "y_pred_distil = np.argmax(preds_distil.predictions, axis=1)\n",
    "\n",
    "print(classification_report(test_labels, y_pred_distil, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQAYWZKoreRk"
   },
   "source": [
    "- near perfect metrics on type specific bullying (F1 0.96–0.99)\n",
    "- solid performance (85% accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gs2p6wRcsVdO"
   },
   "source": [
    "## RoBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ui36WsJhsVoh"
   },
   "source": [
    "1. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3332216d58ca4ca6aee7291f39f22d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bee4606d48440b935932e18bfe189d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e928b446344fed9d623351726e3eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049e58d73ea34d7299666a0b153eff12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da278421f6294fc69b6dc477663923f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_roberta = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "train_encodings_roberta = tokenizer_roberta(list(train_texts), truncation=True, padding=True, max_length=128)\n",
    "test_encodings_roberta = tokenizer_roberta(list(test_texts), truncation=True, padding=True, max_length=128)\n",
    "\n",
    "train_dataset_roberta = CyberbullyingDataset(train_encodings_roberta, list(train_labels))\n",
    "test_dataset_roberta = CyberbullyingDataset(test_encodings_roberta, list(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzUGsrIoshLh"
   },
   "source": [
    "2. Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11577555d08446e4876eefa50edcc2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_roberta = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"roberta-base\", num_labels=len(le.classes_)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTqItFx9sndq"
   },
   "source": [
    "3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-723298419.py:11: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_roberta = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4456' max='4456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4456/4456 24:02, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.409200</td>\n",
       "      <td>0.403278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.308600</td>\n",
       "      <td>0.354933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4456, training_loss=0.39718807364280606, metrics={'train_runtime': 1444.2149, 'train_samples_per_second': 49.36, 'train_steps_per_second': 3.085, 'total_flos': 3480267166422120.0, 'train_loss': 0.39718807364280606, 'epoch': 2.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args_roberta = TrainingArguments(\n",
    "    output_dir='./roberta_results',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_dir='./roberta_logs',\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "trainer_roberta = Trainer(\n",
    "    model=model_roberta,\n",
    "    args=training_args_roberta,\n",
    "    train_dataset=train_dataset_roberta,\n",
    "    eval_dataset=test_dataset_roberta,\n",
    "    tokenizer=tokenizer_roberta\n",
    ")\n",
    "\n",
    "trainer_roberta.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IarKTcOjssqX"
   },
   "source": [
    "4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                age       0.98      0.98      0.98      1588\n",
      "          ethnicity       0.99      0.99      0.99      1501\n",
      "             gender       0.90      0.88      0.89      1527\n",
      "  not_cyberbullying       0.66      0.54      0.60      1322\n",
      "other_cyberbullying       0.66      0.77      0.71      1379\n",
      "           religion       0.95      0.97      0.96      1594\n",
      "\n",
      "           accuracy                           0.87      8911\n",
      "          macro avg       0.86      0.86      0.85      8911\n",
      "       weighted avg       0.87      0.87      0.86      8911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_roberta = trainer_roberta.predict(test_dataset_roberta)\n",
    "y_pred_roberta = np.argmax(preds_roberta.predictions, axis=1)\n",
    "\n",
    "print(classification_report(test_labels, y_pred_roberta, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdBD25K-EY5G"
   },
   "source": [
    "- near perfect on typr specific bullying (F1 0.96–0.99) with excellent balance\n",
    "- solid on not bullying and vague tweets (F1 0.60–0.71)\n",
    "- not cyberbullying (0.54) remains a weak point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yoOHZ7MYuF4J"
   },
   "source": [
    "## Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Model  Accuracy  F1-macro  F1-weighted  Precision-macro  \\\n",
      "0   BERT-base  0.866008  0.854805     0.864337         0.857142   \n",
      "1  DistilBERT  0.865111  0.853237     0.862966         0.855739   \n",
      "2     RoBERTa  0.865784  0.854513     0.864104         0.856377   \n",
      "\n",
      "   Precision-weighted  Recall-macro  Recall-weighted  \n",
      "0            0.866012      0.856154         0.866008  \n",
      "1            0.864632      0.854943         0.865111  \n",
      "2            0.865348      0.855862         0.865784  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# collect metrics for each transformer model\n",
    "results = []\n",
    "\n",
    "def add_results(name, y_true, y_pred):\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"F1-macro\": f1_score(y_true, y_pred, average='macro'),\n",
    "        \"F1-weighted\": f1_score(y_true, y_pred, average='weighted'),\n",
    "        \"Precision-macro\": precision_score(y_true, y_pred, average='macro'),\n",
    "        \"Precision-weighted\": precision_score(y_true, y_pred, average='weighted'),\n",
    "        \"Recall-macro\": recall_score(y_true, y_pred, average='macro'),\n",
    "        \"Recall-weighted\": recall_score(y_true, y_pred, average='weighted')\n",
    "    })\n",
    "\n",
    "# add transformer models\n",
    "add_results(\"BERT-base\", test_labels, y_pred_bert)\n",
    "add_results(\"DistilBERT\", test_labels, y_pred_distil)\n",
    "add_results(\"RoBERTa\", test_labels, y_pred_roberta)\n",
    "\n",
    "# create dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# display resylts\n",
    "print(results_df)\n",
    "\n",
    "# save to CSV\n",
    "results_df.to_csv(\"transformer_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GY7oIBKrROSz"
   },
   "source": [
    "- BERT-base and RoBERTa edge out DistilBERT in most metrics showing robust contextual understanding for attribute specific bullying"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
